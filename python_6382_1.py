# -*- coding: utf-8 -*-
"""Python_6382 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KSxveXpCisaiETPfd8vmnIrzmqp_GaO8
"""

import pickle, csv, pandas as pd, matplotlib.pyplot as plt, numpy as np
from datetime import datetime

class Lodging:
    def __init__(self, date, name, category, type, rating, price, average_revenue):
        self.date = date
        self.name = name
        self.category = category
        self.type = type
        self.rating = rating
        self.price = price
        self.average_revenue = average_revenue
        self.unique_id = id(self)

    def __str__(self):
        return f"{self.unique_id}, {self.date}, {self.name}, {self.category},{self.type}, {self.rating}, {self.price}, {self.average_revenue}"

# date,name,category,rating,price,average_revenue
class Travel(Lodging):
    def __init__(self, date, name, category, rating, price, average_revenue):
        super().__init__(date, name, category, "Travel", rating, price, average_revenue)

class Vacation(Lodging):
    def __init__(self, date, name, category, rating, price, average_revenue):
        super().__init__(date, name, category, "Vacation", rating, price, average_revenue)

# date,name,rating,price,average_revenue
class HotelRoom(Travel):
    def __init__(self, date, name, rating, price, average_revenue):
        super().__init__(date, name, "HotelRoom", rating, price, average_revenue)

class Cottage(Vacation):
    def __init__(self, date, name, rating, price, average_revenue):
        super().__init__(date, name, "Cottage", rating, price, average_revenue)

class BeachHouse(Vacation):
    def __init__(self, date, name, rating, price, average_revenue):
        super().__init__(date, name, "BeachHouse", rating, price, average_revenue)

# Testing the code
VacationLodging = Vacation("2022-10-08","Urban Retreat", "Cottage", 1.0, 85.32, 69020.0)
print(str(VacationLodging))

# Open the pickle file and load the data
with open('Lodgingpkl638250202.dat', 'rb') as f:
    data = pickle.load(f)

# Open the CSV file in write mode
with open('data1.csv', 'w', newline='') as f:
    writer = csv.writer(f)

    # Write the header
    writer.writerow(["unique_id", "date", "name", "category", "type", "rating", "price", "average_revenue"])

    # Write the data
    for obj in data:
        writer.writerow(str(obj).split(','))

df = pd.read_csv('data1.csv')
df.isna().sum() #Need to fill in the data
#could fill in date by category mode (type of stay will heavily affect when people visit) (mode bc the median is more so for continuous data)
#rating could be done by category median
#pricing can be done by category median
#average revenue can be done by pricing (higher pricing -> higher revenue)

df['average_revenue'] = df['average_revenue'].replace(' ', np.nan)
df['average_revenue'] = df['average_revenue'].astype(float)

df['price'] = df['price'].replace(' ', np.nan)
df['price'] = df['price'].astype(float)

df.info()

df['date'] = df['date'].replace(' ', np.nan)
df['date'] = pd.to_datetime(df['date'], dayfirst=False)

df.info()

df.isna().sum()

for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = df[col].replace(' ', np.nan)

df = df.rename(columns = {'unique_id': 'uid'})
df

dfd = df.copy()
dfd.head(10)
dfd.set_index('uid', inplace=True)
dfd

dfd.info()

dfd.isna().sum()

dfd.shape

# Calculate percentage of missing values in each column
missing_percentages = df.isnull().mean() * 100
print("Percentage of missing values in each column:")
print(missing_percentages)

# As the percentage of missing value on average per column is less than 4.2%, we descide to remove the rows containing nan values
# We remove all the rows of the dataframe that contains nan values in the date column
dfd = dfd.dropna(subset=['date'])
dfd.isna().sum()

print(f'shape of the cleaned dataframe is:  {dfd.shape}')

dfd.isnull().sum()

dfd['rating'] = dfd.groupby(['type', 'category', 'name'])['rating'].transform(lambda x: x.fillna(x.mode()[0]))

print(dfd.isnull().sum())
print(dfd.shape)

#dfd['rating'] = dfd.groupby(['type', 'category', 'name'])['price'].transform(lambda x: x.fillna(x.median()[0]))
#dfd['price'] = df.groupby(['type', 'category', 'name'])['price'].transform(lambda x: x.fillna(x.median()))
#dfd['average_revenue'] = df.groupby(['type', 'category', 'name'])['average_revenue'].transform(lambda x: x.fillna(x.median()))
dfd['price'] = dfd.groupby(['type', 'category', 'name'])['price'].transform(lambda x: x.fillna(x.median()))
dfd['average_revenue'] = dfd.groupby(['type', 'category', 'name'])['average_revenue'].transform(lambda x: x.fillna(x.median()))

print(dfd.isnull().sum())
print(dfd.shape)

# Extract year, month, and day into separate columns
dfd['year'] = dfd['date'].dt.year
dfd['month'] = dfd['date'].dt.month
dfd['day'] = dfd['date'].dt.day
dfd.head(10)

#Map numeric month values to month names
month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',
               7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}
dfd['month'] = dfd['month'].map(month_names)
dfd.head(10)

# dropping the date column
# dfd = dfd.drop(columns=['date'], inplace=True)
dfd = dfd.drop('date', axis=1)

cas = df.groupby('category')['average_revenue'].apply(lambda x: x.sum()) # cas stands for category average revenue sum
revenue_percent = []

for category in df.category.unique():
  revenue_percentage = (cas[category]/df.average_revenue.sum()) * 100
  revenue_percent.append(str(round(revenue_percentage, 2))+ '%')

categories = df.category.unique()
piecolors = ['#ff2c2c', '#f1b04c', '#6488ea']

plt.pie(cas, labels = revenue_percent, colors = piecolors)
plt.legend(categories, loc='upper right')
plt.show()

colors = ['#6fc276', '#f1b04c', '#6488ea']
plt.bar(categories, cas, color = colors)
plt.xlabel('Lodging Category')
plt.ylabel('Total Average Revenue')
plt.title('Total Average Revenue by Category')
plt.yticks(np.arange(0,7.5e8, 0.5e8))
plt.show()